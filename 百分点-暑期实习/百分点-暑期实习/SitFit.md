

ğŸ—£ æ— éœ€æç¤ºè¯æˆ–è¯­è¨€å™¨ (verbalisers): ç›®å‰çš„å°‘æ ·æœ¬å¾®è°ƒæŠ€æœ¯éƒ½éœ€è¦æ‰‹å·¥è®¾è®¡çš„æç¤ºæˆ–è¯­è¨€å™¨ï¼Œç”¨äºå°†è®­ç»ƒæ ·æœ¬è½¬æ¢æˆé€‚åˆç›®æ ‡è¯­è¨€æ¨¡å‹çš„æ ¼å¼ã€‚SetFit é€šè¿‡ç›´æ¥ä»å°‘é‡æ ‡æ³¨è®­ç»ƒæ ·æœ¬ä¸­ç”Ÿæˆä¸°å¯Œçš„åµŒå…¥ï¼Œå®Œå…¨çœå»äº†æç¤ºã€‚

ğŸ å¿«é€Ÿè®­ç»ƒ: SetFit ä¸éœ€è¦ä½¿ç”¨åƒ T0 æˆ– GPT-3 è¿™æ ·çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å°±èƒ½è¾¾åˆ°é«˜å‡†ç¡®ç‡ã€‚å› æ­¤ï¼Œå…¸å‹æƒ…å†µä¸‹ï¼Œå®ƒçš„è®­ç»ƒå’Œæ¨ç†ä¼šå¿«ä¸€ä¸ªæ•°é‡çº§æˆ–ä»¥ä¸Šã€‚

ğŸŒ æ”¯æŒå¤šè¯­è¨€: SetFit å¯ä¸ Hub ä¸Šçš„ä»»ä¸€ Sentence Tranformer ä¸€èµ·ä½¿ç”¨ï¼Œè¿™æ„å‘³ç€å¦‚æœä½ æƒ³è®©å®ƒæ”¯æŒå¤šè¯­è¨€æ–‡æœ¬åˆ†ç±»ï¼Œä½ åªè¦ç®€å•åœ°å¾®è°ƒä¸€ä¸ªå¤šè¯­è¨€çš„ checkpoint å°±å¥½äº†ã€‚




> SetFit çš„ä¸¤é˜¶æ®µè®­ç»ƒè¿‡ç¨‹



SetFit ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆåœ¨å°‘é‡æ ‡æ³¨æ ·ä¾‹ (å…¸å‹å€¼æ˜¯æ¯ç±» 8 ä¸ªæˆ– 16 ä¸ªæ ·ä¾‹) ä¸Šå¾®è°ƒä¸€ä¸ª Sentence Transformer æ¨¡å‹ã€‚ç„¶åï¼Œç”¨å¾®è°ƒå¾—åˆ°çš„ Sentence Tranformer çš„æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„åµŒå…¥ (embedding) ï¼Œå¹¶ç”¨è¿™äº›åµŒå…¥è®­ç»ƒä¸€ä¸ªåˆ†ç±»å¤´ (classification head) ã€‚

SetFit åˆ©ç”¨ Sentence Transformer çš„èƒ½åŠ›å»ç”ŸæˆåŸºäºå¥å¯¹ (paired sentences) çš„ç¨ å¯†åµŒå…¥ã€‚


![]("\img\20230712152646.png")


åœ¨ç¬¬ä¸€æ­¥å¾®è°ƒé˜¶æ®µï¼Œå®ƒä½¿ç”¨å¯¹æ¯”è®­ç»ƒ (contrastive training) æ¥æœ€å¤§åŒ–åˆ©ç”¨æœ‰é™çš„æ ‡æ³¨æ•°æ®ã€‚é¦–å…ˆï¼Œé€šè¿‡é€‰æ‹©ç±»å†… (in-class) å’Œç±»å¤– (out-class) å¥å­æ¥æ„é€ æ­£å¥å¯¹å’Œè´Ÿå¥å¯¹ï¼Œç„¶ååœ¨è¿™äº›å¥å¯¹ä¸Šè®­ç»ƒ Sentence Transformer æ¨¡å‹å¹¶ç”Ÿæˆæ¯ä¸ªæ ·æœ¬çš„ç¨ å¯†å‘é‡ã€‚

ç¬¬äºŒæ­¥ï¼Œæ ¹æ®æ¯ä¸ªæ ·æœ¬çš„åµŒå…¥å‘é‡å’Œå„è‡ªçš„ç±»æ ‡ç­¾ï¼Œè®­ç»ƒåˆ†ç±»å¤´ã€‚æ¨ç†æ—¶ï¼Œæœªè§è¿‡çš„æ ·æœ¬é€šè¿‡å¾®è°ƒåçš„ Sentence Transformer å¹¶ç”ŸæˆåµŒå…¥ï¼Œç”Ÿæˆçš„åµŒå…¥éšåè¢«é€å…¥åˆ†ç±»å¤´å¹¶è¾“å‡ºç±»æ ‡ç­¾çš„é¢„æµ‹ã€‚

ç®€è¨€ä¹‹ï¼Œç¬¬ä¸€æ­¥ä½¿ç”¨Sentence Transformerï¼Œç”Ÿæˆæ¯ä¸€ä¸ªæ ·æœ¬ï¼ˆè¯„è®ºï¼‰çš„å‘é‡è¡¨ç¤ºï¼Œè€Œåœ¨ç¬¬äºŒæ­¥åˆ™å°†ç¬¬ä¸€éƒ¨å¯¼å‡ºçš„å‘é‡è¿›è¡Œåˆ†ç±»ã€‚

åªéœ€è¦æŠŠåŸºç¡€ Sentence Transformer æ¨¡å‹æ¢æˆå¤šè¯­è¨€ç‰ˆçš„ï¼ŒSetFit å°±å¯ä»¥æ— ç¼åœ°åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹è¿è¡Œã€‚åœ¨å®éªŒä¸­ï¼ŒSetFit åœ¨å¾·è¯­ã€æ—¥è¯­ã€ä¸­æ–‡ã€æ³•è¯­ä»¥åŠè¥¿ç­ç‰™è¯­ä¸­ï¼Œåœ¨å•è¯­è¨€å’Œè·¨è¯­è¨€çš„æ¡ä»¶ä¸‹ï¼Œéƒ½å–å¾—äº†ä¸é”™çš„åˆ†ç±»æ€§èƒ½ã€‚

**æ³¨ï¼š**å¯¹æ¯”è®­ç»ƒå³å°†æ­£å¥å¯¹x+ï¼ˆåˆ†ç±»ç›¸åŒçš„å¥å­ï¼‰ï¼Œä¸è´Ÿå¥å¯¹x-ï¼ˆåˆ†ç±»ä¸åŒçš„å¥å­ï¼‰

æ¯”å¦‚åœ¨æ”¿æ²»è¨€è®ºä¸­ï¼Œ0ä»£è¡¨ä¸æ˜¯ï¼Œ1ä»£è¡¨æ˜¯ï¼Œ 0ä¸0ï¼Œ1ä¸1æ˜¯æ­£é”®å€¼å¯¹ã€‚10æ˜¯è´Ÿé”®å€¼å¯¹ã€‚
![]("\img\20230712152300.png")


> æµç¨‹

## ä¸¹éº¦è¯­

ç›´æ¥ç¡¬å¥—çš„è¯ä¸¹éº¦è¯­æ•ˆæœä¸å¥½

	# å¯¼å…¥åº“
	! pip install datasets
	! pip install sentence_transformers
	! pip install setfit
	! pip install transformers
	from datasets import load_dataset
	from sentence_transformers.losses import CosineSimilarityLoss
	from setfit import SetFitModel, SetFitTrainer


	# å¯¼å…¥æ•°æ®é›†
	dataset = load_dataset("danish_political_comments")
	# dataset.save_to_disk("./danish_comments")

æŸ¥çœ‹ä¸€ä¸‹æ•°æ®é›†çš„æƒ…å†µ

	dataset

ç»“æœï¼Œå¯ä»¥çœ‹åˆ°æ•°æ®é›†æœ‰ä¸‰ä¸ªfeatureï¼Œid sentence å’Œtargetï¼Œè¦ç”¨çš„æ˜¯sentenceå’Œtarget

	DatasetDict({
	    train: Dataset({
	        features: ['id', 'sentence', 'target'],
	        num_rows: 9008
	    })
	})

ä¸¹éº¦æ•°æ®é›†ä¸è¿›è¡Œæ•°æ®å¤„ç†çš„è¯ä¸€å…±æœ‰å››ç±»å‹æ ‡ç­¾ï¼Œ1,2,3,4ï¼›æ•…éšæœºæ¯ç±»å‹çš„æ ‡ç­¾8ä»½æ•°æ®ã€‚éªŒè¯é›†æ²¡ç±»å‹çš„æ ‡ç­¾100ä»½æ•°æ®ã€‚

	
	# åˆ†å‰²æµ‹è¯•é›†ä¸éªŒè¯é›†
	train_ds = dataset["train"].shuffle(seed=42).select(range(8 * 4))
	test_ds = dataset["train"].shuffle(seed=44).select(range(100 * 4))

	#è¿›è¡Œtrainerçš„åˆå§‹åŒ–ï¼Œæ³¨æ„setFitæ¨¡å‹è¾“å…¥å‚æ•°ä¸ºtextä¸labelï¼Œæ•…éœ€è¦è¿›è¡Œè½¬åŒ–ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚
	column_mapping={"sentence": "text", "target": "label"}
	model = SetFitModel.from_pretrained("sentence-transformers/paraphrase-mpnet-base-v2")
	trainer = SetFitTrainer(
	    model=model,
	    column_mapping=column_mapping,
	    train_dataset=train_ds,
	    eval_dataset=test_ds,
	    loss_class=CosineSimilarityLoss,
	    batch_size=16,
	    num_iterations=20, # Number of text pairs to generate for contrastive learning
	    num_epochs=1 # Number of epochs to use for contrastive learning
	)

è®­ç»ƒ

	trainer.train()
	metrics = trainer.evaluate()

